%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[a4paper,12pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}


\usepackage{amsmath,amsfonts,amssymb,amsthm}

\usepackage{fncychap}
\usepackage{sphinx}
\sphinxsetup{hmargin={0.7in,0.7in}, vmargin={1in,1in},         verbatimwithframe=true,         TitleColor={rgb}{0,0,0},         HeaderFamily=\rmfamily\bfseries,         InnerLinkColor={rgb}{0,0,1},         OuterLinkColor={rgb}{0,0,1}}
\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}


        \setcounter{secnumdepth}{6}
        %
        %%%% Table of content upto 2=subsection, 3=subsubsection
        \setcounter{tocdepth}{3}

        \usepackage{amsmath,amsfonts,amssymb,amsthm}
        \usepackage{graphicx}

        %%% reduce spaces for Table of contents, figures and tables
        %%% it is used "\addtocontents{toc}{\vskip -1.2cm}" etc. in the document
        \usepackage[notlot,nottoc,notlof]{}

        \usepackage{color}
        \usepackage{transparent}
        \usepackage{eso-pic}
        \usepackage{lipsum}

        \usepackage{footnotebackref} %%link at the footnote to go to the place of footnote in the text

        %% spacing between line
        \usepackage{setspace}
        %%%%\onehalfspacing
        %%%%\doublespacing
        \singlespacing


        %%%%%%%%%%% datetime
        \usepackage{datetime}

        \newdateformat{MonthYearFormat}{%
            \monthname[\THEMONTH], \THEYEAR}


        %% RO, LE will not work for 'oneside' layout.
        %% Change oneside to twoside in document class
        \usepackage{fancyhdr}
        \pagestyle{fancy}
        \fancyhf{}

        %%% Alternating Header for oneside
        \fancyhead[L]{\ifthenelse{\isodd{\value{page}}}{ \small \nouppercase{\leftmark} }{}}
        \fancyhead[R]{\ifthenelse{\isodd{\value{page}}}{}{ \small \nouppercase{\rightmark} }}

        %%% Alternating Header for two side
        %\fancyhead[RO]{\small \nouppercase{\rightmark}}
        %\fancyhead[LE]{\small \nouppercase{\leftmark}}

        %% for oneside: change footer at right side. If you want to use Left and right then use same as header defined above.
        \fancyfoot[R]{\ifthenelse{\isodd{\value{page}}}{{\tiny Alessandro Vuan} }{\href{http://github.com/avuan/PyMPA37}{\tiny http://github.com/avuan/PyMPA37}}}

        %%% Alternating Footer for two side
        %\fancyfoot[RO, RE]{\scriptsize Alessandro Vuan (avuan@inogs.it)}

        %%% page number
        \fancyfoot[CO, CE]{\thepage}

        \renewcommand{\headrulewidth}{0.5pt}
        \renewcommand{\footrulewidth}{0.5pt}

        \RequirePackage{tocbibind} %%% comment this to remove page number for following
        \addto\captionsenglish{\renewcommand{\contentsname}{Table of contents}}
        \addto\captionsenglish{\renewcommand{\listfigurename}{List of figures}}
        \addto\captionsenglish{\renewcommand{\listtablename}{List of tables}}
        % \addto\captionsenglish{\renewcommand{\chaptername}{Chapter}}


        %%reduce spacing for itemize
        \usepackage{enumitem}
        \setlist{nosep}

        %%%%%%%%%%% Quote Styles at the top of chapter
        \usepackage{epigraph}
        \setlength{\epigraphwidth}{0.8\columnwidth}
        \newcommand{\chapterquote}[2]{\epigraphhead[60]{\epigraph{\textit{#1}}{\textbf {\textit{--#2}}}}}
        %%%%%%%%%%% Quote for all places except Chapter
        \newcommand{\sectionquote}[2]{{\quote{\textit{``#1''}}{\textbf {\textit{--#2}}}}}
    

\title{PyMPA Python Matching Phase Algorithm Documentation}
\date{Apr 12, 2019}
\release{1.0.0}
\author{Alessandro Vuan and Monica Sugan}
\newcommand{\sphinxlogo}{\sphinxincludegraphics{logo.jpg}\par}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}

        \pagenumbering{Roman} %%% to avoid page 1 conflict with actual page 1

        \begin{titlepage}
            \centering

            \vspace*{40mm} %%% * is used to give space from top
            \textbf{\Huge {Python Matching Phase Algorithm}}

            \vspace{0mm}
            \begin{figure}[!h]
                \centering
                \includegraphics[scale=0.3]{logo.jpg}
            \end{figure}

            \vspace{0mm}
            \Large \textbf{{Alessandro Vuan}}
            \Large \textbf{{Monica Sugan}}

            \small Created on : April, 2019

            \vspace*{0mm}
            \small  Last updated : \MonthYearFormat\today


            %% \vfill adds at the bottom
            \vfill
            \small \textit{More documents are freely available at }{\href{https://github.com/avuan/PyMPA37}{PyMPA}}
        \end{titlepage}

        \clearpage
        \pagenumbering{roman}
        \tableofcontents
        \listoffigures
        \listoftables
        \clearpage
        \pagenumbering{arabic}

        
\pagestyle{plain}
 
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}\sphinxhref{https://github.com/avuan/PyMPA37/docs}{\sphinxincludegraphics[width=100\sphinxpxdimen]{{pympa_logo1}.png}}


PyMPA is designed to detect microseismicity from the cross-correlation of continuous data and templates. PyMPA is an open source seismological software and consists of some separate utilities for input preparation, the main program, and output post-processing tools to obtain a catalogue and verify events. The code repository with some examples is stored on , and is free to be cloned on your Mac, Windows or Linux platforms. It supports Python 2.7, 3.5, 3.6 and 3.7 releases and uses ObsPy for reading and writing seismic data, and for handling most of the event-station metadata. A flowchart of the main program is shown in Figure 1. Matched-filter correlations are calculated using a vectorised python function or using ObsPy v.1.2.0 correlate\_template function allowing to select time or frequency domain.
Together with the manual, we also provide some practical examples. Python scripts, updates and modifications are automatically verified using TRAVIS, for testing and deployment (\sphinxurl{https://travis-ci.org/}). This package is distributed under the LGPL GNU Licence, Copyright PyMPA developers 2019.

The algorithm, which exploits  routines (Krischer et al., 2015), is versatile and supports most commonly used seismic data and earthquake catalogue formats. In addition to PyMPA, we develop other tools external to the main code to manage the input-output preparation and validation for (1) downloading data from Observatories and Research Facilities for European Seismology\textendash{}European Integrated Data Archive (ORFEUS-EIDA) servers, (2) evaluating data quality, (3) selecting earthquakes as templates from a reference catalog, (4) trimming and filtering them from continuous waveforms, (5) avoiding redundant detections in the output, and (6) validating new events. The repository will continue to grow and develop, and any modification will be promptly reported.

Important: we recommend to use an updated version of .
\sphinxhref{https://github.com/avuan/PyMPA37/docs}{\sphinxincludegraphics[width=600\sphinxpxdimen]{{pympa_logo}.png}}
Example of detection using PyMPA. Templates (red waveforms) overlapped on continuous data (black) filtered from 3 to 8 Hz are shown. On the left
for the used channels the corresponding cross-correlation value.

This package contains:
\begin{itemize}
\item {} 
{\hyperref[\detokenize{sub/input.download_data::doc}]{\sphinxcrossref{\DUrole{doc}{Routines for downloading data from eida servers}}}};

\item {} 
{\hyperref[\detokenize{sub/input.create_templates::doc}]{\sphinxcrossref{\DUrole{doc}{Routines for creating and trimming templates}}}};

\item {} 
{\hyperref[\detokenize{sub/input.calculate_ttimes::doc}]{\sphinxcrossref{\DUrole{doc}{Routines for calculating moveout time for synchronization}}}};

\item {} 
{\hyperref[\detokenize{sub/input.template_check::doc}]{\sphinxcrossref{\DUrole{doc}{Kurtosis based template verification}}}};

\item {} 
{\hyperref[\detokenize{sub/main.pympa::doc}]{\sphinxcrossref{\DUrole{doc}{Template matching by using daily estimation of MAD and all the available channels}}}};

\item {} 
{\hyperref[\detokenize{sub/output.process_detections::doc}]{\sphinxcrossref{\DUrole{doc}{Postprocessing routines}}}};

\item {} 
{\hyperref[\detokenize{sub/output.verify_detection::doc}]{\sphinxcrossref{\DUrole{doc}{Visual verification of detections}}}};

\end{itemize}

This package is written by the PyMPA developers, and is distributed under the LGPL GNU Licence, Copyright PyMPA developers 2019.

Acknowledgements

The software development was partially funded by a joint research project within the
executive program of scientific and technological cooperation between Italy
and Japan for the period 2013\textendash{}2015. Additional funds for software development
come from the project “Seismology and Earthquake Engineering
Research Infrastructure Alliance for Europe” (SERA), responding to the priorities
identified in the call INFRAIA-01-2016-2017 Research Infrastructure
for Earthquake Hazard. We thank Monica Sugan for the extensive testing of the codes and Aitaro Kato
at the Earthquake Research Institute (ERI) in Tokyo for fruitful
discussions.
The authors also wish to thank the ObsPy community for the continuous
support and constant development of related libraries.

Citation

If you use this package in your work, please cite the following papers:

Vuan A., Sugan M., Amati G., Kato A., 2017 - Improving the Detection of Low-Magnitude Seismicity Preceding the Mw 6.3 L’Aquila Earthquake: Development of a Scalable Code Based on the Cross-Correlation of Template Earthquakes, BSSA \sphinxurl{https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/525813/improving-the-detection-of-low-magnitude?redirectedFrom=fulltext}

Vuan A., Sugan M., Chiaraluce L., Di Stefano R., 2017 - Loading rate variations along a mid-crustal shear zone preceding the MW6.0 earthquake of the 24th of August 2016 in Central Italy, Geophysical Research Letters \sphinxurl{http://onlinelibrary.wiley.com/doi/10.1002/2017GL076223/full}

Sugan, M., Vuan, A., Kato, A., Massa, M., \& Amati, G. (2019). Seismic evidence of an early afterslip during the 2012 sequence in Emilia (Italy). Geophysical Research Letters, 46, 625\textendash{}635. \sphinxurl{https://doi.org/10.1029/2018GL079617}

Contents


\chapter{Introduction to the PyMPA package}
\label{\detokenize{intro:introduction-to-the-pympa-package}}\label{\detokenize{intro::doc}}
This document is designed to give you an overview of the capabilities and
implementation of the PyMPA Python package.


\section{Motivation}
\label{\detokenize{intro:motivation}}
PyMPA is designed to augment the detection capability of earthquakes, or any seismic signal
(explosions or low frequency tremors) by using advanced routines different from the faster standard
amplitude-ratio STA/LTA methods.

The technique allows to improve seismic catalogs
decreasing the completeness magnitude and is particularly useful in detecting seismicity below
the background noise level, and during a strong aftershocks sequence when the network sensitivity is lower.
PyMPA is based on MFT search for
earthquakes that resemble well-located events, termed templates (e.g., Shelly
et al., 2007; Peng and Zhao, 2009; Yang et al., 2009; Kato et al., 2012; Zhang and
Wen, 2015). The algorithm, which exploits ObsPy routines (Krischer et al., 2015), is
versatile and supports most commonly used seismic data and earthquake catalog
formats. A PyMPA flowchart is also shown below.
\sphinxhref{https://github.com/avuan/PyMPA37/releases}{\sphinxincludegraphics[width=800\sphinxpxdimen]{{flowchart}.png}}
In addition to PyMPA, we develop other tools external
to the main code to manage the input\textendash{}output preparation and
validation for (1) downloading data from Observatories and
Research Facilities for European Seismology\textendash{}European
Integrated Data Archive (ORFEUS-EIDA) servers, (2) evaluating
data quality, (3) selecting earthquakes as templates
from a reference catalog, (4) trimming and filtering them
from continuous waveforms, (5) avoiding redundant detections
in the output, and (6) validating new events.
This repository will continue to grow and develop
and any modification will be reported in the github repository.


\section{Supported environments}
\label{\detokenize{intro:supported-environments}}
Linux, OSX and Windows environments running Python 2.7 and 3.x.
We will stop support for Python 2.7 in a forthcoming release.


\section{Functionality}
\label{\detokenize{intro:functionality}}
Within {\hyperref[\detokenize{input::doc}]{\sphinxcrossref{\DUrole{doc}{input}}}} you will find the routines to generate templates,
({\hyperref[\detokenize{sub/input.create_templates::doc}]{\sphinxcrossref{\DUrole{doc}{create\_template}}}}) select good templates
({\hyperref[\detokenize{sub/input.template_check::doc}]{\sphinxcrossref{\DUrole{doc}{template\_check}}}}), calculate travel times
({\hyperref[\detokenize{sub/input.calculate_ttimes::doc}]{\sphinxcrossref{\DUrole{doc}{calculate\_ttimes}}}}),
compute cross-channel correlations from these templates
({\hyperref[\detokenize{sub/main.pympa::doc}]{\sphinxcrossref{\DUrole{doc}{pympa}}}}), process\_detections
({\hyperref[\detokenize{sub/output.process_detections::doc}]{\sphinxcrossref{\DUrole{doc}{process\_detections}}}}), and apply for visual inspection
({\hyperref[\detokenize{sub/output.verify_detection::doc}]{\sphinxcrossref{\DUrole{doc}{verify\_detection}}}})


\section{Running tests}
\label{\detokenize{intro:running-tests}}
For running tests examples are provided in the github subdirectories, tests are recalled
when modifications are performed to the codes and a TRAVIS CI report is released.

You can also run these tests by yourself locally to ensure
that everything runs as you would expect in your environment.

Although every effort has been made to ensure these tests run smoothly on all supported environments
, if you do find any issues, please let us know on the
 page.


\section{References}
\label{\detokenize{intro:references}}
Shelly, D. R., G. C. Beroza, and S. Ide (2007). Non-volcanic tremor and low
frequency earthquake swarms, Nature 446, 305\textendash{}307.

Peng, Z., and P. Zhao (2009). Migration of early aftershocks following the
2004 Parkfield earthquake, Nature Geosci. 2, 877\textendash{}881.

Yang, H., L. Zhu, and R. Chu (2009). Fault-plane determination of the
18 April 2008 Mount Carmel, Illinois, earthquake by detecting and
relocating aftershocks, Bull. Seismol. Soc. Am. 99, 3413\textendash{}3420.

Kato, A., K. Obara, T. Igarashi, H. Tsuruoka, S. Nakagawa, and N. Hirata
(2012). Propagation of slow slip leading up to the 2011 Mw 9.0
Tohoku-Oki earthquake, Science 335, 705\textendash{}708.

Zhang, M., and L. Wen (2015). An effective method for small event detection:
Match and locate (M\&L), Geophys. J. Int. 200, 1523\textendash{}1537.

Krischer, L., T. Megies, R. Barsch, M. Beyreuther, T. Lecocq, C. Caudron,
and J. Wassermann (2015). ObsPy: A bridge for seismology into the
scientific Python ecosystem, Comput. Sci. Discov. 8, no. 1, 014003,
doi: 10.1088/1749-4699/8/1/014003.
\sphinxhref{https://github.com/avuan/PyMPA37/releases}{\sphinxincludegraphics[width=100\sphinxpxdimen]{{pympa_logo1}.png}}

\chapter{PyMPA installation}
\label{\detokenize{installation:pympa-installation}}\label{\detokenize{installation::doc}}
PyMPA is a pure Python package. It runs after the installation of a virtual
environment with Numpy, Scipy, Matplotlib and Obspy libraries.
Some C extensions of ObsPy toolkit are also used and Bottleneck libraries.
Bottleneck is a set of functions inspired by NumPy and SciPy, but written in
Cython with high performance in mind. Bottleneck provides separate Cython
functions for each combination of array dimensions, axis, and data type.

We heavily recommend installing ObsPy using conda because:
\begin{itemize}
\item {} 
separate your install from your system default Python,
avoiding to have problems with your OS;

\item {} 
correct compilation is more probable

\end{itemize}

If you do not have either a miniconda or anaconda installation you can follow
the  instructions.

If you do not already have a conda environment we recommend creating one
with the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
conda create \PYGZhy{}n obspy \PYG{n+nv}{python}\PYG{o}{=}\PYG{l+m}{3}.6
conda activate obspy
conda install obspy
conda install bottleneck
\end{sphinxVerbatim}

For installing PyMPA you can simply clone the git repository and try it within your obspy env:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
git clone git@github.com:avuan/PyMPA37.git
\end{sphinxVerbatim}

On a Linux system for installing conda, obspy, bottleneck and mirror the PyMPA code follow this commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
curl \PYGZhy{}O https://repo.continuum.io/archive/Anaconda3\PYGZhy{}5.0.1\PYGZhy{}Linux\PYGZhy{}x86\PYGZus{}64.sh
chmod +x Anaconda3\PYGZhy{}5.0.1\PYGZhy{}Linux\PYGZhy{}x86\PYGZus{}64.sh
./Anaconda3\PYGZhy{}5.0.1\PYGZhy{}Linux\PYGZhy{}x86\PYGZus{}64.sh
\PYG{n+nb}{source} ˜.bashrc
conda config \PYGZhy{}\PYGZhy{}add channels conda\PYGZhy{}forge
conda create \PYGZhy{}n obspy37 \PYG{n+nv}{python}\PYG{o}{=}\PYG{l+m}{3}.7
\PYG{n+nb}{source} activate obspy37
conda install obspy
conda install bottleneck
mkdir test\PYGZus{}obspy1.2.0
\PYG{n+nb}{cd} test\PYGZus{}obspy1.2.0
git clone https://github.com/avuan/PyMPA37
\end{sphinxVerbatim}
\sphinxhref{https://github.com/avuan/PyMPA37/releases}{\sphinxincludegraphics[width=100\sphinxpxdimen]{{pympa_logo1}.png}}

\chapter{Tutorial}
\label{\detokenize{tutorial:tutorial}}\label{\detokenize{tutorial::doc}}
This tutorial is designed to give you an overview of the capabilities and
implementation of the PyMPA Python package.


\section{Downloading Seismological Data}
\label{\detokenize{tutorial:downloading-seismological-data}}
To download seismological data from EIDA (European Integrated Data Archive) servers:
Data from broad band seismic stations are available
from many European Institutions. To download seismological data from EIDA (European Integrated Data Archive) servers
and inventory data in STATIONXML format many examples can also be found in ObsPy.

PyMPA requires, continuous data and stations inventories.
EIDA servers can easily release data from permanent networks and the corresponding
inventories. The examples in the subdirectory input.download\_data.dir show the python scripts
that allows the download.

In the case your data come from other sources, PyMPA through ObsPy libraries
is able to manage most of the seismological data formats (MSEED, SAC, SEISAN, SEGY, etc..).
An inventory data file including station information needs to be created by modifying an existing
StationXML file.

PyMPA does not use databases and prefers to store single channel daily continuous data in archieves or subdirectories.

Executable files:
\begin{itemize}
\item {} 
download\_data.py (\sphinxurl{https://github.com/avuan/PyMPA37/tree/master/input.download\_data.dir/download\_data.py})

\item {} 
download\_inventory.py (\sphinxurl{https://github.com/avuan/PyMPA37/tree/master/input.download\_data.dir/download\_inventory.py})

\end{itemize}

({\hyperref[\detokenize{sub/input.download_data::doc}]{\sphinxcrossref{\DUrole{doc}{download\_data}}}}) download data


\section{Create Templates}
\label{\detokenize{tutorial:create-templates}}
({\hyperref[\detokenize{sub/input.create_templates::doc}]{\sphinxcrossref{\DUrole{doc}{create\_template}}}}) create templates

A Python script create\_templates.py is used to trim templates from continuous data and inventories
stored in an archive. Generally, we use travel times to cut events before and after S-wave arrivals.
Thus, a reference 1D velocity model is needed. Trimmed waveforms have to be carefully checked to evaluate
the effectiveness of S-wave travel time calculations.
Take care that a high sampling rate could result in memory consumption
and prolonged times of execution.
Input data should be decimated a priori accordingly with your needs and availability of cores.
Check the example for running create\_templates.py at \sphinxurl{https://github.com/avuan/PyMPA37/tree/master/input.create\_templates.dir}

Executable file:
\begin{itemize}
\item {} 
create\_templates.py (\sphinxurl{https://github.com/avuan/PyMPA37/tree/master/input.create\_templates.dir/create\_templates.py})

\end{itemize}

Input parameters:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}Line 1 \PYGZhy{}\PYGZhy{} list of stations}
\PYG{c+c1}{\PYGZsh{}Line 2 \PYGZhy{}\PYGZhy{} list of channels}
\PYG{c+c1}{\PYGZsh{}Line 3 \PYGZhy{}\PYGZhy{} list of networks}
\PYG{c+c1}{\PYGZsh{}Line 4 \PYGZhy{}\PYGZhy{} Lowpass frequency}
\PYG{c+c1}{\PYGZsh{}Line 5 \PYGZhy{}\PYGZhy{} Highpass frequency}
\PYG{c+c1}{\PYGZsh{}Line 6 \PYGZhy{}\PYGZhy{} Trimmed Time before S\PYGZhy{}wave}
\PYG{c+c1}{\PYGZsh{}Line 7 \PYGZhy{}\PYGZhy{} Trimmed Time after S\PYGZhy{}wave}
\PYG{c+c1}{\PYGZsh{}Line 8 \PYGZhy{}\PYGZhy{} UTC precision}
\PYG{c+c1}{\PYGZsh{}Line 9 \PYGZhy{}\PYGZhy{} Continuous data dir}
\PYG{c+c1}{\PYGZsh{}Line 10 \PYGZhy{}\PYGZhy{} Template data dir}
\PYG{c+c1}{\PYGZsh{}Line 11 \PYGZhy{}\PYGZhy{} Processing days list }
\PYG{c+c1}{\PYGZsh{}Line 12 \PYGZhy{}\PYGZhy{} Zmap catalog}
\PYG{c+c1}{\PYGZsh{}Line 13 \PYGZhy{}\PYGZhy{} Starting template}
\PYG{c+c1}{\PYGZsh{}Line 14 \PYGZhy{}\PYGZhy{} Stopping template}
\PYG{c+c1}{\PYGZsh{}Line 15 \PYGZhy{}\PYGZhy{} Taup Model}
\PYG{n}{AQU} \PYG{n}{CAMP} \PYG{n}{CERT} \PYG{n}{FAGN} \PYG{n}{FIAM} \PYG{n}{GUAR} \PYG{n}{INTR} \PYG{n}{MNS} \PYG{n}{NRCA} \PYG{n}{TERO}
\PYG{n}{BHE} \PYG{n}{BHN} \PYG{n}{BHZ}
\PYG{n}{IV} \PYG{n}{MN}
\PYG{l+m+mf}{2.0}
\PYG{l+m+mf}{8.0}
\PYG{l+m+mf}{2.5}
\PYG{l+m+mf}{2.5}
\PYG{l+m+mi}{6}
\PYG{l+m+mi}{24}\PYG{n}{h}
\PYG{n}{template}
\PYG{n}{lista1}
\PYG{n}{templates}\PYG{o}{.}\PYG{n}{zmap}
\PYG{l+m+mi}{26}
\PYG{l+m+mi}{27}
\PYG{n}{aquila\PYGZus{}kato}
\end{sphinxVerbatim}

Note that input and output file names, inventories, template catalogs, velocity models are recalled also in the next steps.


\section{Check Template Quality}
\label{\detokenize{tutorial:check-template-quality}}
({\hyperref[\detokenize{sub/input.template_check::doc}]{\sphinxcrossref{\DUrole{doc}{template\_check}}}}) select good templates

Evaluating template quality allows to input only a good signal to noise ratio avoiding artifacts resulting in unwanted detections. The selection is based on Kurtosis method (\sphinxurl{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosis.html}) supposing that the waveform is simmetrically trimmed at the first S-wave arrival. Kurtosis evaluates if the time distrbution of amplitudes is simmetric or not excluding data having a low signal to noise ratio.
Peak amplitudes at the beginning or in the signal coda are unwanted and a selection is also made to exclude them.

Check examples running test\_kurtosis1.py at \sphinxurl{https://github.com/avuan/PyMPA37/tree/master/input.template\_check.dir}
After running kurtosis based selection,
templates are separated in two subdirectories “bad”(red waveforms see figure below) and “good” (black waveforms see figure below)

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{bad}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{bad4}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{bad7}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{good}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{good1}.png}\hspace*{\fill}}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=400\sphinxpxdimen]{{good3}.png}\hspace*{\fill}}

Executable python scripts:
\begin{itemize}
\item {} 
template\_check1.py at \sphinxurl{https://github.com/avuan/PyMPA37/tree/master/input.template\_check.dir/template\_check1.py} (performs on waveform)

\item {} 
template\_check2.py at \sphinxurl{https://github.com/avuan/PyMPA37/tree/master/input.template\_check.dir/template\_check2.py} (performs on the absolute values of waveform)

\end{itemize}


\section{Calculate Travel Times}
\label{\detokenize{tutorial:calculate-travel-times}}
({\hyperref[\detokenize{sub/input.calculate_ttimes::doc}]{\sphinxcrossref{\DUrole{doc}{calculate\_ttimes}}}}) calculate travel times

Travel time calculation is based on Java TauP Toolkit as implemented in ObsPy (\sphinxurl{https://docs.obspy.org/packages/obspy.taup.html})
Travel times are needed for synchronization to obtain a stacked cross-correlation function. It is supposed that trimmed templates
are stored in ./template directory. The same reference 1D velocity model used for trimming templates is needed.

Executable file:
\begin{itemize}
\item {} 
calculate\_ttimes.py at \sphinxurl{https://github.com/avuan/PyMPA37/tree/master/input.calculate\_ttimes.dir/calculate\_ttimes.py}

\end{itemize}

Input parameters:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}Line 1 \PYGZhy{}\PYGZhy{} list of stations}
\PYG{c+c1}{\PYGZsh{}Line 2 \PYGZhy{}\PYGZhy{} list of channels}
\PYG{c+c1}{\PYGZsh{}Line 3 \PYGZhy{}\PYGZhy{} list of networks}
\PYG{c+c1}{\PYGZsh{}Line 4 \PYGZhy{}\PYGZhy{} Lowpass frequency}
\PYG{c+c1}{\PYGZsh{}Line 5 \PYGZhy{}\PYGZhy{} Highpass frequency}
\PYG{c+c1}{\PYGZsh{}Line 6 \PYGZhy{}\PYGZhy{} Trimmed Time before S\PYGZhy{}wave}
\PYG{c+c1}{\PYGZsh{}Line 7 \PYGZhy{}\PYGZhy{} Trimmed Time after S\PYGZhy{}wave}
\PYG{c+c1}{\PYGZsh{}Line 8 \PYGZhy{}\PYGZhy{} UTC precision}
\PYG{c+c1}{\PYGZsh{}Line 9 \PYGZhy{}\PYGZhy{} Continuous data dir}
\PYG{c+c1}{\PYGZsh{}Line 10 \PYGZhy{}\PYGZhy{} Template data dir}
\PYG{c+c1}{\PYGZsh{}Line 11 \PYGZhy{}\PYGZhy{} Processing days list }
\PYG{c+c1}{\PYGZsh{}Line 12 \PYGZhy{}\PYGZhy{} Zmap catalog}
\PYG{c+c1}{\PYGZsh{}Line 13 \PYGZhy{}\PYGZhy{} Starting template}
\PYG{c+c1}{\PYGZsh{}Line 14 \PYGZhy{}\PYGZhy{} Stopping template}
\PYG{c+c1}{\PYGZsh{}Line 15 \PYGZhy{}\PYGZhy{} Taup Model }
\PYG{n}{AQU} \PYG{n}{CAMP} \PYG{n}{CERT} \PYG{n}{FAGN} \PYG{n}{FIAM} \PYG{n}{GUAR} \PYG{n}{INTR} \PYG{n}{MNS} \PYG{n}{NRCA} \PYG{n}{TERO}
\PYG{n}{BHE} \PYG{n}{BHN} \PYG{n}{BHZ}
\PYG{n}{IV} \PYG{n}{MN}
\PYG{l+m+mf}{2.0}
\PYG{l+m+mf}{8.0}
\PYG{l+m+mf}{2.5}
\PYG{l+m+mf}{2.5}
\PYG{l+m+mi}{6}
\PYG{n}{template}
\PYG{n}{ttimes1}
\PYG{n}{lista1}
\PYG{n}{templates}\PYG{o}{.}\PYG{n}{zmap}
\PYG{l+m+mi}{26}
\PYG{l+m+mi}{27}
\PYG{n}{aquila\PYGZus{}kato}
\end{sphinxVerbatim}

Note that input and output file names, inventories, template catalogs, velocity models are recalled also in the next steps.


\section{Running PyMPA}
\label{\detokenize{tutorial:running-pympa}}
Template matching code, using cross-correlation based on well located events. The code is embarassingly parallel and different templates/days can be run on different cores. We do not provide the scripts to parallelize jobs preferring to leave to the user to find the best strategy to accomplish the task. We generally prefer to distribute the workload by using Slurm.

Executable files:
\begin{itemize}
\item {} 
pympa.py (working on daily chunks and with a reduced number of channels). Chunking daily data results in MAD calculated on the working time window.

\end{itemize}

Input parameters:

Input parameters are described line by line in parameters24 file

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} input parameters for runnig 27 version}
\PYG{c+c1}{\PYGZsh{} line1 = stations available,}
\PYG{c+c1}{\PYGZsh{} line2 = channels available,}
\PYG{c+c1}{\PYGZsh{} line3 = networks available,}
\PYG{c+c1}{\PYGZsh{} line4 = low bandpass filter frequency,}
\PYG{c+c1}{\PYGZsh{} line5 = high bandpass filter frequency,}
\PYG{c+c1}{\PYGZsh{} line6 = sample tolerance in detecting maximum cft amplitude for each channel,}
\PYG{c+c1}{\PYGZsh{} line7 = cross\PYGZhy{}correlation threshold to be overcome by cft,}
\PYG{c+c1}{\PYGZsh{} line8 = min number of channels overcoming the cross\PYGZhy{}correlation threshold,}
\PYG{c+c1}{\PYGZsh{} line9 = template duration(s),}
\PYG{c+c1}{\PYGZsh{} line10 = UTCDateTime.DEFAULT\PYGZus{}PRECISION (number of digits considered in fractions of seconds),}
\PYG{c+c1}{\PYGZsh{} line11 = string variable containing the directory name for continuous 24h waveforms,}
\PYG{c+c1}{\PYGZsh{} line12 = string variable for templates\PYGZsq{} directory,}
\PYG{c+c1}{\PYGZsh{} line13 = string variable for travel times directory,}
\PYG{c+c1}{\PYGZsh{} line14 = filename for day list to process,}
\PYG{c+c1}{\PYGZsh{} line15 = filename for zmap catalog,}
\PYG{c+c1}{\PYGZsh{} line16 = template start number,}
\PYG{c+c1}{\PYGZsh{} line17 = template stop number(if line16==0  and line17==0 all templates are processed,}
\PYG{c+c1}{\PYGZsh{} line18 = multiplying factor for MAD to determine threshold }
\PYG{c+c1}{\PYGZsh{} line 19 = multiplying factor to remove daily cft channels with std greater than (average std from all channels * factor at at line 19) }
\PYG{c+c1}{\PYGZsh{} line 20 = multiplying factor to remove daily cft channels with std smaller than (average std from all channels * factor at at line 20)}
\PYG{c+c1}{\PYGZsh{} line 21 = maximum number of templates to be used in template matching (choice is made preferring the closest channels)}
\PYG{c+c1}{\PYGZsh{} line 22 = number of chunks per day (1=86400s, 2=43200, 3=28800, 4=21600, 6=14400 etc... icreasing the factor allows reducing memory consumption) }
\PYG{n}{APEC} \PYG{n}{ATBU} \PYG{n}{ATCA} \PYG{n}{ATCC} \PYG{n}{ATFO} \PYG{n}{ATLO} \PYG{n}{ATPC} \PYG{n}{ATPI} \PYG{n}{ATSC} \PYG{n}{ATVO} \PYG{n}{BADI} \PYG{n}{FOSV} \PYG{n}{FRON} \PYG{n}{MURB} \PYG{n}{NARO} \PYG{n}{PARC} \PYG{n}{PIEI} \PYG{n}{PE3} \PYG{n}{SSFR}
\PYG{n}{EHE} \PYG{n}{EHN} \PYG{n}{EHZ} \PYG{n}{HHE} \PYG{n}{HHN} \PYG{n}{HHZ}
\PYG{n}{IV}
\PYG{l+m+mf}{3.0}
\PYG{l+m+mf}{8.0}
\PYG{l+m+mi}{6}
\PYG{l+m+mf}{0.35}
\PYG{l+m+mi}{6}
\PYG{l+m+mi}{5}
\PYG{l+m+mi}{6}
\PYG{l+m+mi}{24}\PYG{n}{h}
\PYG{n}{template}
\PYG{n}{ttimes}
\PYG{n}{lista1}
\PYG{n}{templates}\PYG{o}{.}\PYG{n}{zmap}
\PYG{l+m+mi}{200}
\PYG{l+m+mi}{203}
\PYG{l+m+mi}{8}
\PYG{l+m+mf}{1.5}
\PYG{l+m+mf}{0.25}
\PYG{l+m+mi}{12}
\PYG{l+m+mi}{6}
\end{sphinxVerbatim}


\section{Output Processing}
\label{\detokenize{tutorial:output-processing}}
({\hyperref[\detokenize{sub/output.process_detections::doc}]{\sphinxcrossref{\DUrole{doc}{output.process\_detections}}}}) controls multiple detections in short time windows

A bash script calling python code performs the catalog sythesis. Some templates could concur to the same detection. The detection
showing the highest threshold value is preferred in a fix time window (e.g. 6 seconds).

Executable file:
\begin{itemize}
\item {} 
bash script postproc37.sh

\item {} 
process\_detections.py at \sphinxurl{https://github.com/avuan/PyMPA37/tree/master/output.process\_detections.dir/process\_detections.py}

\end{itemize}

Input parameters:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} Line 1 \PYGZhy{} FlagDateTime (Enter 1 for timestamp format (2009\PYGZhy{}03\PYGZhy{}30T21:59:43.616111Z) or Enter 0 for having seconds in a day (for plotting)) }
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} Line 2 \PYGZhy{} Flag\PYGZus{}cc (1 to have returned the best results in terms of average cross\PYGZhy{}corr using the sample tolerance, 0 results at sample tolerance 0)}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} Line 3 \PYGZhy{} Input file}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} Line 4 \PYGZhy{} UTC precison used in time }
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} Line 5 \PYGZhy{} window\PYGZus{}length (half time window for searching unique events)}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} Line 6 \PYGZhy{} min\PYGZus{}threshold (threshold used in parameters24 for detecting events,  threshold * MAD)}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} Line 7 \PYGZhy{} min\PYGZus{}nch (minimum number of channels to overcome the setup cc value in parameters24 e.g. 0.6)}
\PYG{l+m+mi}{1} 
\PYG{l+m+mi}{1} 
\PYG{o}{.}\PYG{o}{/}\PYG{n}{dcat}
\PYG{l+m+mi}{6} 
\PYG{l+m+mf}{3.0} 
\PYG{l+m+mf}{8.0} 
\PYG{l+m+mi}{7} 
\end{sphinxVerbatim}


\section{Verify Detections}
\label{\detokenize{tutorial:verify-detections}}
({\hyperref[\detokenize{sub/output.verify_detection::doc}]{\sphinxcrossref{\DUrole{doc}{output.verify\_detection}}}}) for visual verification of events

Produce graphics windows showing the continuous data overlapped by templates events at the detection time.

Executable file:
\begin{itemize}
\item {} 
verify\_detection.py at \sphinxurl{https://github.com/avuan/PyMPA37/tree/master/output.verify\_detection.dir/verify\_detection.py}

\end{itemize}

Input parameters:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Line 1 \PYGZhy{}\PYGZhy{} list of stations}
\PYG{c+c1}{\PYGZsh{} Line 2 \PYGZhy{}\PYGZhy{} list of channels}
\PYG{c+c1}{\PYGZsh{} Line 3 \PYGZhy{}\PYGZhy{} list of networks}
\PYG{c+c1}{\PYGZsh{} Line 4 \PYGZhy{}\PYGZhy{} Lowpass frequency}
\PYG{c+c1}{\PYGZsh{} Line 5 \PYGZhy{}\PYGZhy{} Highpass frequency}
\PYG{c+c1}{\PYGZsh{} Line 6 \PYGZhy{}\PYGZhy{} Trimmed Time before S\PYGZhy{}wave}
\PYG{c+c1}{\PYGZsh{} Line 7 \PYGZhy{}\PYGZhy{} Trimmed Time after S\PYGZhy{}wave}
\PYG{c+c1}{\PYGZsh{} Line 8 \PYGZhy{}\PYGZhy{} UTC precision}
\PYG{c+c1}{\PYGZsh{} Line 9 \PYGZhy{}\PYGZhy{} Continuous data dir}
\PYG{c+c1}{\PYGZsh{} Line 10 \PYGZhy{}\PYGZhy{} Template data dir}
\PYG{c+c1}{\PYGZsh{} Line 11 \PYGZhy{}\PYGZhy{} Ttimes data dir  }
\PYG{c+c1}{\PYGZsh{} Line 12 \PYGZhy{}\PYGZhy{} Zmap catalog}
\PYG{c+c1}{\PYGZsh{} Line 13 \PYGZhy{}\PYGZhy{} Starting detection}
\PYG{c+c1}{\PYGZsh{} Line 14 \PYGZhy{}\PYGZhy{} Stopping detection}
\PYG{c+c1}{\PYGZsh{} Line 15 \PYGZhy{}\PYGZhy{} Half of the visualized time window in sec }
\PYG{c+c1}{\PYGZsh{} Line 16 \PYGZhy{}\PYGZhy{} Taup Model }
\PYG{c+c1}{\PYGZsh{} Line 17 \PYGZhy{}\PYGZhy{} Flag\PYGZus{}Save\PYGZus{}Fig (0 = show, 1 = save figure)}
\PYG{c+c1}{\PYGZsh{} Line 18 \PYGZhy{}\PYGZhy{} Flag\PYGZus{}Read\PYGZus{}Stats (0 = no stats, 1 = read stats) }
\PYG{c+c1}{\PYGZsh{} Line 19 \PYGZhy{}\PYGZhy{} Tolerance in time between outcat origin time and stats}
\PYG{n}{ATBU} \PYG{n}{ATFO} \PYG{n}{ATLO} \PYG{n}{ATMI} \PYG{n}{ATPC} \PYG{n}{ATPI} \PYG{n}{ATSC} \PYG{n}{ATVO} \PYG{n}{BADI} \PYG{n}{CDCA} \PYG{n}{MURB}
\PYG{n}{EHE} \PYG{n}{EHN} \PYG{n}{EHZ} \PYG{n}{HHE} \PYG{n}{HHN} \PYG{n}{HHZ}
\PYG{n}{IV} \PYG{n}{MN}
\PYG{l+m+mf}{3.0}
\PYG{l+m+mf}{8.0}
\PYG{l+m+mf}{2.5}
\PYG{l+m+mf}{2.5}
\PYG{l+m+mi}{6}
\PYG{l+m+mi}{24}\PYG{n}{h}
\PYG{n}{template}
\PYG{n}{ttimes}
\PYG{n}{templates}\PYG{o}{.}\PYG{n}{zmap}
\PYG{l+m+mi}{0}
\PYG{l+m+mi}{5}
\PYG{l+m+mi}{10}
\PYG{n}{ato}
\PYG{l+m+mi}{1}
\PYG{l+m+mi}{1}
\PYG{l+m+mf}{0.05}
\end{sphinxVerbatim}


\section{References}
\label{\detokenize{tutorial:references}}
Shelly, D. R., G. C. Beroza, and S. Ide (2007). Non-volcanic tremor and low
frequency earthquake swarms, Nature 446, 305\textendash{}307.

Peng, Z., and P. Zhao (2009). Migration of early aftershocks following the
2004 Parkfield earthquake, Nature Geosci. 2, 877\textendash{}881.

Yang, H., L. Zhu, and R. Chu (2009). Fault-plane determination of the
18 April 2008 Mount Carmel, Illinois, earthquake by detecting and
relocating aftershocks, Bull. Seismol. Soc. Am. 99, 3413\textendash{}3420.

Kato, A., K. Obara, T. Igarashi, H. Tsuruoka, S. Nakagawa, and N. Hirata
(2012). Propagation of slow slip leading up to the 2011 Mw 9.0
Tohoku-Oki earthquake, Science 335, 705\textendash{}708.

Zhang, M., and L. Wen (2015). An effective method for small event detection:
Match and locate (M\&L), Geophys. J. Int. 200, 1523\textendash{}1537.

Krischer, L., T. Megies, R. Barsch, M. Beyreuther, T. Lecocq, C. Caudron,
and J. Wassermann (2015). ObsPy: A bridge for seismology into the
scientific Python ecosystem, Comput. Sci. Discov. 8, no. 1, 014003,
doi: 10.1088/1749-4699/8/1/014003.
\sphinxhref{https://github.com/avuan/PyMPA37/releases}{\sphinxincludegraphics[width=100\sphinxpxdimen]{{pympa_logo1}.png}}

\chapter{Preprocessing Input}
\label{\detokenize{input:preprocessing-input}}\label{\detokenize{input::doc}}
This package contains utilities for:
\begin{itemize}
\item {} 
{\hyperref[\detokenize{sub/input.download_data::doc}]{\sphinxcrossref{\DUrole{doc}{Routines for downloading data from eida servers}}}};

\item {} 
{\hyperref[\detokenize{sub/input.create_templates::doc}]{\sphinxcrossref{\DUrole{doc}{Routines for creating and trimming templates}}}};

\item {} 
{\hyperref[\detokenize{sub/input.calculate_ttimes::doc}]{\sphinxcrossref{\DUrole{doc}{Routines for calculating moveout time for synchronization}}}};

\item {} 
{\hyperref[\detokenize{sub/input.template_check::doc}]{\sphinxcrossref{\DUrole{doc}{Kurtosis based template verification}}}};

\end{itemize}

These utilities are written by the PyMPA developers, and are distributed under the LGPL GNU Licence, Copyright PyMPA developers 2019.


\section{Contents:}
\label{\detokenize{input:contents}}

\subsection{Download data}
\label{\detokenize{sub/input.download_data:download-data}}\label{\detokenize{sub/input.download_data::doc}}
Downloading data from EIDA servers is easily performed by using ObsPy tools
and routines. Please see the scripts at \sphinxurl{https://github.com/avuan/PyMPA37/blob/master/input.download\_data.dir/}

download\_data.py and download\_inventory.py allows downloading continuous data and inventories for the selected stations
and time period.

For some networks or stations please check before data availability or if there are some restrictions and a token
or userid is needed. Some EIDA servers when receiving from the same user many requests in a short time
close the door to the user. That is the reason why we introduced a pause command in our scripts, this avoids
the shutdown of the connection.

Here below a simple code to download continuous data,

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/usr/bin/env python}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{}*\PYGZhy{} coding: utf\PYGZhy{}8 \PYGZhy{}*\PYGZhy{}}
\PYG{c+c1}{\PYGZsh{}}

\PYG{k+kn}{import} \PYG{n+nn}{time}
\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{k+kn}{from} \PYG{n+nn}{obspy}\PYG{n+nn}{.}\PYG{n+nn}{clients}\PYG{n+nn}{.}\PYG{n+nn}{fdsn} \PYG{k}{import} \PYG{n}{Client}
\PYG{k+kn}{from} \PYG{n+nn}{obspy}\PYG{n+nn}{.}\PYG{n+nn}{core}\PYG{n+nn}{.}\PYG{n+nn}{utcdatetime} \PYG{k}{import} \PYG{n}{UTCDateTime}

\PYG{n}{client} \PYG{o}{=} \PYG{n}{Client}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{INGV}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{networks} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{IV}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{}}
\PYG{n}{stations}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{MURB}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{NARO}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

\PYG{n}{channels} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{EH*}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{HH*}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

\PYG{n}{start} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{2012\PYGZhy{}02\PYGZhy{}05T00:00:00.000}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{stop} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{2012\PYGZhy{}02\PYGZhy{}06T00:00:00.000}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} 24h as seconds}
\PYG{n}{chuncklength} \PYG{o}{=} \PYG{l+m+mi}{86400}

\PYG{c+c1}{\PYGZsh{} output directory}
\PYG{n}{inp\PYGZus{}dir} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./24h/}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} output directory}
\PYG{k}{if} \PYG{o+ow}{not} \PYG{n}{os}\PYG{o}{.}\PYG{n}{path}\PYG{o}{.}\PYG{n}{exists}\PYG{p}{(}\PYG{n}{inp\PYGZus{}dir}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{os}\PYG{o}{.}\PYG{n}{makedirs}\PYG{p}{(}\PYG{n}{inp\PYGZus{}dir}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}do not change below}

\PYG{k}{for} \PYG{n}{sta} \PYG{o+ow}{in} \PYG{n}{stations}\PYG{p}{:}
    \PYG{n}{t1} \PYG{o}{=} \PYG{p}{(}\PYG{n}{UTCDateTime}\PYG{p}{(}\PYG{n}{start}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{timestamp}
    \PYG{n}{t3} \PYG{o}{=} \PYG{p}{(}\PYG{n}{UTCDateTime}\PYG{p}{(}\PYG{n}{stop}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{timestamp}
    \PYG{n}{t2} \PYG{o}{=} \PYG{n}{t1} \PYG{o}{+} \PYG{n}{chuncklength}

    \PYG{k}{while} \PYG{n}{t2} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{n}{t3}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{station == }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{sta}\PYG{p}{)}

        \PYG{k}{for} \PYG{n}{net} \PYG{o+ow}{in} \PYG{n}{networks}\PYG{p}{:}

            \PYG{k}{for} \PYG{n}{chann} \PYG{o+ow}{in} \PYG{n}{channels}\PYG{p}{:}

                \PYG{k}{try}\PYG{p}{:}
                    \PYG{n}{bulk} \PYG{o}{=} \PYG{p}{[}\PYG{p}{(}\PYG{n}{net}\PYG{p}{,} \PYG{n}{sta}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{*}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{chann}\PYG{p}{,} \PYG{n}{UTCDateTime}\PYG{p}{(}
                        \PYG{n}{t1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{UTCDateTime}\PYG{p}{(}\PYG{n}{t2}\PYG{p}{)}\PYG{p}{)}\PYG{p}{]}
                    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bulk == }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{bulk}\PYG{p}{)}
                    \PYG{n}{yy} \PYG{o}{=} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{UTCDateTime}\PYG{p}{(}\PYG{n}{t1}\PYG{p}{)}\PYG{o}{.}\PYG{n}{year}\PYG{p}{)}
                    \PYG{n}{mm} \PYG{o}{=} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{UTCDateTime}\PYG{p}{(}\PYG{n}{t1}\PYG{p}{)}\PYG{o}{.}\PYG{n}{month}\PYG{p}{)}\PYG{o}{.}\PYG{n}{zfill}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}
                    \PYG{n}{dd} \PYG{o}{=} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{UTCDateTime}\PYG{p}{(}\PYG{n}{t1}\PYG{p}{)}\PYG{o}{.}\PYG{n}{day}\PYG{p}{)}\PYG{o}{.}\PYG{n}{zfill}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}

                    \PYG{n}{newfile} \PYG{o}{=} \PYG{n}{inp\PYGZus{}dir} \PYG{o}{+} \PYG{n}{yy} \PYG{o}{+} \PYG{n}{mm} \PYG{o}{+} \PYG{n}{dd} \PYG{o}{+}\PYGZbs{}
                        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{.}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{+} \PYG{n}{sta} \PYG{o}{+} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{.}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{+} \PYG{n}{chann}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{3}\PYG{p}{]}
                    \PYG{n}{client}\PYG{o}{.}\PYG{n}{get\PYGZus{}waveforms\PYGZus{}bulk}\PYG{p}{(}\PYG{n}{bulk}\PYG{p}{,} \PYG{n}{filename}\PYG{o}{=}\PYG{n}{newfile}\PYG{p}{)}
                    \PYG{n}{time}\PYG{o}{.}\PYG{n}{sleep}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}
                \PYG{k}{except} \PYG{n+ne}{Exception}\PYG{p}{:}
                    \PYG{n}{time}\PYG{o}{.}\PYG{n}{sleep}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}
                    \PYG{k}{pass}

        \PYG{n}{t1} \PYG{o}{=} \PYG{n}{t1} \PYG{o}{+} \PYG{n}{chuncklength}
        \PYG{n}{t2} \PYG{o}{=} \PYG{n}{t2} \PYG{o}{+} \PYG{n}{chuncklength}
\end{sphinxVerbatim}

and for downloading station inventories

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/usr/bin/env python}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{}*\PYGZhy{} coding: utf\PYGZhy{}8 \PYGZhy{}*\PYGZhy{}}
\PYG{c+c1}{\PYGZsh{}}
\PYG{k+kn}{from} \PYG{n+nn}{obspy}\PYG{n+nn}{.}\PYG{n+nn}{clients}\PYG{n+nn}{.}\PYG{n+nn}{fdsn} \PYG{k}{import} \PYG{n}{Client}
\PYG{k+kn}{from} \PYG{n+nn}{obspy}\PYG{n+nn}{.}\PYG{n+nn}{core}\PYG{n+nn}{.}\PYG{n+nn}{utcdatetime} \PYG{k}{import} \PYG{n}{UTCDateTime}


\PYG{n}{client} \PYG{o}{=} \PYG{n}{Client}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{INGV}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{starttime} \PYG{o}{=} \PYG{n}{UTCDateTime}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{2011\PYGZhy{}01\PYGZhy{}01}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{endtime} \PYG{o}{=} \PYG{n}{UTCDateTime}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{2017\PYGZhy{}06\PYGZhy{}30}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{inventory} \PYG{o}{=} \PYG{n}{client}\PYG{o}{.}\PYG{n}{get\PYGZus{}stations}\PYG{p}{(}
    \PYG{n}{starttime}\PYG{o}{=}\PYG{n}{starttime}\PYG{p}{,} \PYG{n}{endtime}\PYG{o}{=}\PYG{n}{endtime}\PYG{p}{,}
    \PYG{n}{network}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{MN}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{sta}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{AQU}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{channel}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{*}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{filename}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{inv.aqu}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{xml}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{inventory}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Create templates}
\label{\detokenize{sub/input.create_templates:create-templates}}\label{\detokenize{sub/input.create_templates::doc}}
Actually templates are created by trimming a fixed time window focused on S-wave theoretical travel times. For details on the travel time calculations see \sphinxurl{file:///Users/vuan/PycharmProjects/PyMPA37/docs/build/html/tutorial.html\#calculate-travel-times}.

The length of the time window is established by the inter-statiion network distance and the frequency range used.
The user should carefully check to exclude signal deriving from numerical artifacts (e.g. filtering applied to zero padding
time windows having no data), or pre and coda signals not connected with the seismic perturbation investigated (e.g. LFEs, earthquakes, icequakes etc…)
In the next versions the trimming will allow for selecting variable length P and S-waves.

Needed files:
\begin{itemize}
\item {} 
Events in a catalog: e.g. templates.zmap (quakeml or zmap format) see ObsPy for more details. An example of zmap file format is given here below (ZMAP is a simple 10 column CSV file (technically TSV) format for basic catalog data. It originates from ZMAP, a Matlab® based earthquake statistics package (see {[}Wiemer2001{]}).

\item {} 
Columns represent: longitude, latitude, year, month, day, magnitude, depth, hour, minute, second - note that fields have to be separated by tabs.

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m+mf}{13.38347} \PYG{l+m+mf}{42.38842} \PYG{l+m+mi}{2009} \PYG{l+m+mi}{03} \PYG{l+m+mi}{30} \PYG{l+m+mf}{1.3} \PYG{l+m+mf}{11.180} \PYG{l+m+mi}{14} \PYG{l+m+mi}{04} \PYG{l+m+mf}{34.50}
\PYG{l+m+mf}{13.38981} \PYG{l+m+mf}{42.33004} \PYG{l+m+mi}{2009} \PYG{l+m+mi}{03} \PYG{l+m+mi}{30} \PYG{l+m+mf}{1.5} \PYG{l+m+mf}{9.170} \PYG{l+m+mi}{14} \PYG{l+m+mi}{15} \PYG{l+m+mf}{4.32}
\PYG{l+m+mf}{13.39447} \PYG{l+m+mf}{42.32878} \PYG{l+m+mi}{2009} \PYG{l+m+mi}{03} \PYG{l+m+mi}{30} \PYG{l+m+mf}{1.6} \PYG{l+m+mf}{9.610} \PYG{l+m+mi}{14} \PYG{l+m+mi}{16} \PYG{l+m+mf}{6.35}
\PYG{l+m+mf}{13.40577} \PYG{l+m+mf}{42.31941} \PYG{l+m+mi}{2009} \PYG{l+m+mi}{03} \PYG{l+m+mi}{30} \PYG{l+m+mf}{1.4} \PYG{l+m+mf}{5.370} \PYG{l+m+mi}{14} \PYG{l+m+mi}{17} \PYG{l+m+mf}{1.74}
\PYG{l+m+mf}{13.36791} \PYG{l+m+mf}{42.59639} \PYG{l+m+mi}{2009} \PYG{l+m+mi}{03} \PYG{l+m+mi}{30} \PYG{l+m+mf}{1.3} \PYG{l+m+mf}{5.710} \PYG{l+m+mi}{14} \PYG{l+m+mi}{35} \PYG{l+m+mf}{16.74}
\PYG{l+m+mf}{13.45651} \PYG{l+m+mf}{42.25600} \PYG{l+m+mi}{2009} \PYG{l+m+mi}{03} \PYG{l+m+mi}{30} \PYG{l+m+mf}{1.3} \PYG{l+m+mf}{5.620} \PYG{l+m+mi}{14} \PYG{l+m+mi}{42} \PYG{l+m+mf}{23.29}
\PYG{l+m+mf}{13.38686} \PYG{l+m+mf}{42.31381} \PYG{l+m+mi}{2009} \PYG{l+m+mi}{03} \PYG{l+m+mi}{30} \PYG{l+m+mf}{1.2} \PYG{l+m+mf}{6.270} \PYG{l+m+mi}{15} \PYG{l+m+mi}{10} \PYG{l+m+mf}{34.73}
\PYG{l+m+mf}{13.49527} \PYG{l+m+mf}{42.30006} \PYG{l+m+mi}{2009} \PYG{l+m+mi}{03} \PYG{l+m+mi}{30} \PYG{l+m+mf}{0.9} \PYG{l+m+mf}{6.810} \PYG{l+m+mi}{15} \PYG{l+m+mi}{21} \PYG{l+m+mf}{2.28}
\PYG{l+m+mf}{13.32714} \PYG{l+m+mf}{42.33182} \PYG{l+m+mi}{2009} \PYG{l+m+mi}{03} \PYG{l+m+mi}{30} \PYG{l+m+mf}{1.4} \PYG{l+m+mf}{6.210} \PYG{l+m+mi}{15} \PYG{l+m+mi}{40} \PYG{l+m+mf}{5.62}
\PYG{l+m+mf}{13.29606} \PYG{l+m+mf}{42.27235} \PYG{l+m+mi}{2009} \PYG{l+m+mi}{03} \PYG{l+m+mi}{30} \PYG{l+m+mf}{1.2} \PYG{l+m+mf}{8.690} \PYG{l+m+mi}{15} \PYG{l+m+mi}{53} \PYG{l+m+mf}{5.35}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Suitable velocity model for computing travel times

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{aquila} \PYG{o}{+} \PYG{n}{ak135}
\PYG{n}{depth} \PYG{n}{P} \PYG{n}{vel}\PYG{o}{.} \PYG{n}{S} \PYG{n}{vel}\PYG{o}{.} \PYG{n}{density} \PYG{n}{older} \PYG{n}{density}
     \PYG{l+m+mf}{0.000}      \PYG{l+m+mf}{3.7500}      \PYG{l+m+mf}{2.1650}      \PYG{l+m+mf}{2.4500} 
     \PYG{l+m+mf}{1.500}      \PYG{l+m+mf}{3.7500}      \PYG{l+m+mf}{2.1710}      \PYG{l+m+mf}{2.4500}
     \PYG{l+m+mf}{1.510}      \PYG{l+m+mf}{4.9400}      \PYG{l+m+mf}{2.8520}      \PYG{l+m+mf}{2.7800}
     \PYG{l+m+mf}{4.510}      \PYG{l+m+mf}{4.9400}      \PYG{l+m+mf}{2.8580}      \PYG{l+m+mf}{2.7800}
     \PYG{l+m+mf}{4.520}      \PYG{l+m+mf}{6.0100}      \PYG{l+m+mf}{3.2790}      \PYG{l+m+mf}{2.7600}
    \PYG{l+m+mf}{14.520}      \PYG{l+m+mf}{6.0100}      \PYG{l+m+mf}{3.2850}      \PYG{l+m+mf}{2.7600}
    \PYG{l+m+mf}{14.530}      \PYG{l+m+mf}{5.5500}      \PYG{l+m+mf}{3.3950}      \PYG{l+m+mf}{2.9100}
    \PYG{l+m+mf}{29.530}      \PYG{l+m+mf}{5.5500}      \PYG{l+m+mf}{3.4010}      \PYG{l+m+mf}{2.9100}
    \PYG{l+m+mf}{29.540}      \PYG{l+m+mf}{5.8800}      \PYG{l+m+mf}{4.0990}      \PYG{l+m+mf}{3.1000}
    \PYG{l+m+mf}{43.540}      \PYG{l+m+mf}{5.8800}      \PYG{l+m+mf}{4.1050}      \PYG{l+m+mf}{3.1000}
    \PYG{l+m+mf}{43.550}      \PYG{l+m+mf}{5.8800}      \PYG{l+m+mf}{4.5610}      \PYG{l+m+mf}{3.1000}
    \PYG{l+m+mf}{57.500}      \PYG{l+m+mf}{5.8800}      \PYG{l+m+mf}{3.3600}      \PYG{l+m+mf}{3.1000}
    \PYG{l+m+mf}{57.500}      \PYG{l+m+mf}{7.1100}      \PYG{l+m+mf}{4.0100}      \PYG{l+m+mf}{3.2300}
    \PYG{l+m+mf}{93.000}      \PYG{l+m+mf}{7.1100}      \PYG{l+m+mf}{4.0100}      \PYG{l+m+mf}{3.2300}
    \PYG{l+m+mf}{93.000}      \PYG{l+m+mf}{7.1000}      \PYG{l+m+mf}{3.9900}      \PYG{l+m+mf}{3.3000}
   \PYG{l+m+mf}{136.500}      \PYG{l+m+mf}{7.1000}      \PYG{l+m+mf}{3.9900}      \PYG{l+m+mf}{3.3000} 
   \PYG{l+m+mf}{165.000}      \PYG{l+m+mf}{8.1750}      \PYG{l+m+mf}{4.5090}      \PYG{l+m+mf}{3.3487} 
   \PYG{l+m+mf}{210.000}      \PYG{l+m+mf}{8.3000}      \PYG{l+m+mf}{4.5180}      \PYG{l+m+mf}{3.3960}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Station inventory (format consistent with ObsPy read\_inventory routine see \sphinxurl{https://docs.obspy.org/packages/autogen/obspy.core.inventory.inventory.read\_inventory.html})

\item {} 
Days to process: one column file including days to process e.g. lista1

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m+mi}{090330}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Set parameters: e.g. trim.par

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}Line 1 \PYGZhy{}\PYGZhy{} list of stations}
\PYG{c+c1}{\PYGZsh{}Line 2 \PYGZhy{}\PYGZhy{} list of channels}
\PYG{c+c1}{\PYGZsh{}Line 3 \PYGZhy{}\PYGZhy{} list of networks}
\PYG{c+c1}{\PYGZsh{}Line 4 \PYGZhy{}\PYGZhy{} Lowpass frequency}
\PYG{c+c1}{\PYGZsh{}Line 5 \PYGZhy{}\PYGZhy{} Highpass frequency}
\PYG{c+c1}{\PYGZsh{}Line 6 \PYGZhy{}\PYGZhy{} Trimmed Time before S\PYGZhy{}wave}
\PYG{c+c1}{\PYGZsh{}Line 7 \PYGZhy{}\PYGZhy{} Trimmed Time after S\PYGZhy{}wave}
\PYG{c+c1}{\PYGZsh{}Line 8 \PYGZhy{}\PYGZhy{} UTC precision}
\PYG{c+c1}{\PYGZsh{}Line 9 \PYGZhy{}\PYGZhy{} Continuous data dir}
\PYG{c+c1}{\PYGZsh{}Line 10 \PYGZhy{}\PYGZhy{} Template data dir}
\PYG{c+c1}{\PYGZsh{}Line 11 \PYGZhy{}\PYGZhy{} Processing days list }
\PYG{c+c1}{\PYGZsh{}Line 12 \PYGZhy{}\PYGZhy{} Zmap catalog}
\PYG{c+c1}{\PYGZsh{}Line 13 \PYGZhy{}\PYGZhy{} Starting template}
\PYG{c+c1}{\PYGZsh{}Line 14 \PYGZhy{}\PYGZhy{} Stopping template}
\PYG{c+c1}{\PYGZsh{}Line 15 \PYGZhy{}\PYGZhy{} Taup Model}
\PYG{n}{AQU} \PYG{n}{CAMP} \PYG{n}{CERT} \PYG{n}{FAGN} \PYG{n}{FIAM} \PYG{n}{GUAR} \PYG{n}{INTR} \PYG{n}{MNS} \PYG{n}{NRCA} \PYG{n}{TERO}
\PYG{n}{BHE} \PYG{n}{BHN} \PYG{n}{BHZ}
\PYG{n}{IV} \PYG{n}{MN}
\PYG{l+m+mf}{2.0}
\PYG{l+m+mf}{8.0}
\PYG{l+m+mf}{2.5}
\PYG{l+m+mf}{2.5}
\PYG{l+m+mi}{6}
\PYG{l+m+mi}{24}\PYG{n}{h}
\PYG{n}{template}
\PYG{n}{lista1}
\PYG{n}{templates}\PYG{o}{.}\PYG{n}{zmap}
\PYG{l+m+mi}{26}
\PYG{l+m+mi}{27}
\PYG{n}{aquila\PYGZus{}kato}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Directory i.e. ./24h where 24h continuous data are stored

\item {} 
Output dir i.e. ./template (find trimmed time series)

\end{itemize}

Note that input and output file names, inventories, template catalogs, velocity models are recalled also in the next steps and remain almost fixed. Parameters in files .par could change.

References
Wiemer S. (2001), A software package to analyzeseismicity: ZMAP, Seismol Res Lett 92, 373-382


\subsection{Calculate Travel Times}
\label{\detokenize{sub/input.calculate_ttimes:calculate-travel-times}}\label{\detokenize{sub/input.calculate_ttimes::doc}}
Theoretical travel-time arrivals are calculated using the ObsPy port of the Java TauP Toolkit routines, see \sphinxurl{https://docs.obspy.org/packages/obspy.taup.html} (Crotwell et al., 1999).
For using your own earth model see \sphinxurl{https://docs.obspy.org/packages/autogen/obspy.taup.taup\_create.build\_taup\_model.html\#obspy.taup.taup\_create.build\_taup\_model}
Model initialization is an expensive operation. Thus, make sure to do it only if necessary.
ObsPy include custom built models can be initialized by specifying an absolute path to a model in ObsPy’s .npz model format instead of just a model name. See below for information on how to build a .npz model file.
Building an ObsPy model file from a “tvel” or “nd” file is easy.

An example of tvel model to be compiled by build\_taup\_model Obspy function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{aquila} \PYG{o}{+} \PYG{n}{ak135}
\PYG{n}{depth} \PYG{n}{P} \PYG{n}{vel}\PYG{o}{.} \PYG{n}{S} \PYG{n}{vel}\PYG{o}{.} \PYG{n}{density} \PYG{n}{older} \PYG{n}{density}
     \PYG{l+m+mf}{0.000}      \PYG{l+m+mf}{3.7500}      \PYG{l+m+mf}{2.1650}      \PYG{l+m+mf}{2.4500} 
     \PYG{l+m+mf}{1.500}      \PYG{l+m+mf}{3.7500}      \PYG{l+m+mf}{2.1710}      \PYG{l+m+mf}{2.4500}
     \PYG{l+m+mf}{1.510}      \PYG{l+m+mf}{4.9400}      \PYG{l+m+mf}{2.8520}      \PYG{l+m+mf}{2.7800}
     \PYG{l+m+mf}{4.510}      \PYG{l+m+mf}{4.9400}      \PYG{l+m+mf}{2.8580}      \PYG{l+m+mf}{2.7800}
     \PYG{l+m+mf}{4.520}      \PYG{l+m+mf}{6.0100}      \PYG{l+m+mf}{3.2790}      \PYG{l+m+mf}{2.7600}
    \PYG{l+m+mf}{14.520}      \PYG{l+m+mf}{6.0100}      \PYG{l+m+mf}{3.2850}      \PYG{l+m+mf}{2.7600}
    \PYG{l+m+mf}{14.530}      \PYG{l+m+mf}{5.5500}      \PYG{l+m+mf}{3.3950}      \PYG{l+m+mf}{2.9100}
    \PYG{l+m+mf}{29.530}      \PYG{l+m+mf}{5.5500}      \PYG{l+m+mf}{3.4010}      \PYG{l+m+mf}{2.9100}
\end{sphinxVerbatim}

Needed files:
\begin{itemize}
\item {} 
Events in a catalog: e.g. templates.zmap (quakeml or zmap format) see ObsPy for format

\item {} 
Suitable velocity model for computing travel times

\item {} 
Station inventory (format consistent with ObsPy read\_inventory routine see \sphinxurl{https://docs.obspy.org/packages/autogen/obspy.core.inventory.inventory.read\_inventory.html})

\item {} 
Days to process: one column file including days to process e.g. lista1

\item {} 
Set parameters: e.g. times.par

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}Line 1 \PYGZhy{}\PYGZhy{} list of stations}
\PYG{c+c1}{\PYGZsh{}Line 2 \PYGZhy{}\PYGZhy{} list of channels}
\PYG{c+c1}{\PYGZsh{}Line 3 \PYGZhy{}\PYGZhy{} list of networks}
\PYG{c+c1}{\PYGZsh{}Line 4 \PYGZhy{}\PYGZhy{} Lowpass frequency}
\PYG{c+c1}{\PYGZsh{}Line 5 \PYGZhy{}\PYGZhy{} Highpass frequency}
\PYG{c+c1}{\PYGZsh{}Line 6 \PYGZhy{}\PYGZhy{} Trimmed Time before S\PYGZhy{}wave}
\PYG{c+c1}{\PYGZsh{}Line 7 \PYGZhy{}\PYGZhy{} Trimmed Time after S\PYGZhy{}wave}
\PYG{c+c1}{\PYGZsh{}Line 8 \PYGZhy{}\PYGZhy{} UTC precision}
\PYG{c+c1}{\PYGZsh{}Line 9 \PYGZhy{}\PYGZhy{} Continuous data dir}
\PYG{c+c1}{\PYGZsh{}Line 10 \PYGZhy{}\PYGZhy{} Template data dir}
\PYG{c+c1}{\PYGZsh{}Line 11 \PYGZhy{}\PYGZhy{} Processing days list }
\PYG{c+c1}{\PYGZsh{}Line 12 \PYGZhy{}\PYGZhy{} Zmap catalog}
\PYG{c+c1}{\PYGZsh{}Line 13 \PYGZhy{}\PYGZhy{} Starting template}
\PYG{c+c1}{\PYGZsh{}Line 14 \PYGZhy{}\PYGZhy{} Stopping template}
\PYG{c+c1}{\PYGZsh{}Line 15 \PYGZhy{}\PYGZhy{} Taup Model }
\PYG{n}{AQU} \PYG{n}{CAMP} \PYG{n}{CERT} \PYG{n}{FAGN} \PYG{n}{FIAM} \PYG{n}{GUAR} \PYG{n}{INTR} \PYG{n}{MNS} \PYG{n}{NRCA} \PYG{n}{TERO}
\PYG{n}{BHE} \PYG{n}{BHN} \PYG{n}{BHZ}
\PYG{n}{IV} \PYG{n}{MN}
\PYG{l+m+mf}{2.0}
\PYG{l+m+mf}{8.0}
\PYG{l+m+mf}{2.5}
\PYG{l+m+mf}{2.5}
\PYG{l+m+mi}{6}
\PYG{n}{template}
\PYG{n}{ttimes1}
\PYG{n}{lista1}
\PYG{n}{templates}\PYG{o}{.}\PYG{n}{zmap}
\PYG{l+m+mi}{26}
\PYG{l+m+mi}{27}
\PYG{n}{aquila\PYGZus{}kato}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Input directory i.e. ./template where trimmed templates are found

\item {} 
Output dir i.e. ./ttimes (find moveout times from different channels used to synchronize cross-correlation functions)

\end{itemize}

References

Crotwell, H. P., T. J. Owens, and J. Ritsema (1999). The TauP Toolkit:
Flexible seismic travel-time and ray-path utilities, Seismol. Res. Lett.
70, 154\textendash{}160.


\subsection{Template Kurtosis-based Waveform Check}
\label{\detokenize{sub/input.template_check:template-kurtosis-based-waveform-check}}\label{\detokenize{sub/input.template_check::doc}}
The input data quality of continuous waveforms is verified by testing daily gaps and overlapping streams and ensuring that a certain percentage of the requested time span is available. To obtain accurate results, input preparation is critical, and template waveforms should be carefully checked before running PyMPA. Filter frequency band selection depends on the best signal-to-noise ratio of templates and is related to the structural model and epicentral distances involved.
 statistics is used to evaluate the simmetry of the time series neglecting from the pool of trimmed templates
waveforms that show high simmetry in the S-wave selected time window. It is supposed that low signal to noise ratios
have low values of  index. This contributes to exclude the template/channel from the estimation of the cross-correlation.
The routine avoids also signals or glitches that are located at the beginning and at the end of the signal (please check carefully the code before using it).
Scipy  is used as a standard routine.

(see \sphinxurl{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosis.html})

An example using the input\_template\_check is provided also showing accpted and removed waveforms.
\sphinxhref{https://github.com/avuan/PyMPA37/releases}{\sphinxincludegraphics[width=100\sphinxpxdimen]{{pympa_logo1}.png}}

\chapter{Main Program}
\label{\detokenize{main:main-program}}\label{\detokenize{main::doc}}
PyMPA procedure provides the detection of microseismicity starting from well located templates by using a cross-correlation function from a network.
The code is stored on , and can be freely cloned on your platform. It supports Python 2.7, 3.4, 3.5, 3.6, 3.7
releases and uses  for reading and writing seismic data, and for handling most
of the event metadata. Matched-filter correlations are calculated using a python normalised cross-correlation function or the
ObsPy v. 1.2.0  released on April
2019. Detections can be also obtained using a single station and three channels by modifying the input parameters (thresholds etc..).
This version is running on a single core and does not include multiprocessing routines. However, in the need of massive calculations for years and thousands
of templates, it could be easily implemented a script using SLURM or other schedulers to submit many jobs to the available processors.

Important: we recommend to use an updated version of ObsPy.

Main packages contains:
\begin{itemize}
\item {} 
{\hyperref[\detokenize{sub/main.pympa::doc}]{\sphinxcrossref{\DUrole{doc}{Template matching by using daily estimation of MAD and all the available channels}}}};

\end{itemize}

This package is written by the PyMPA developers, and is distributed under the LGPL GNU Licence, Copyright PyMPA developers 2019.


\section{Contents:}
\label{\detokenize{main:contents}}

\subsection{Running PyMPA}
\label{\detokenize{sub/main.pympa:running-pympa}}\label{\detokenize{sub/main.pympa::doc}}
The input files are those prepared in advance by using pre-processing tools. The only input file that changes is the parameters24 input file.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} input parameters for runnig 27 version}
\PYG{c+c1}{\PYGZsh{} line1 = stations available,}
\PYG{c+c1}{\PYGZsh{} line2 = channels available,}
\PYG{c+c1}{\PYGZsh{} line3 = networks available,}
\PYG{c+c1}{\PYGZsh{} line4 = low bandpass filter frequency,}
\PYG{c+c1}{\PYGZsh{} line5 = high bandpass filter frequency,}
\PYG{c+c1}{\PYGZsh{} line6 = sample tolerance in detecting maximum cft amplitude for each channel,}
\PYG{c+c1}{\PYGZsh{} line7 = cross\PYGZhy{}correlation threshold to be overcome by cft,}
\PYG{c+c1}{\PYGZsh{} line8 = min number of channels overcoming the cross\PYGZhy{}correlation threshold,}
\PYG{c+c1}{\PYGZsh{} line9 = template duration(s),}
\PYG{c+c1}{\PYGZsh{} line10 = UTCDateTime.DEFAULT\PYGZus{}PRECISION (number of digits considered in fractions of seconds),}
\PYG{c+c1}{\PYGZsh{} line11 = string variable containing the directory name for continuous 24h waveforms,}
\PYG{c+c1}{\PYGZsh{} line12 = string variable for templates\PYGZsq{} directory,}
\PYG{c+c1}{\PYGZsh{} line13 = string variable for travel times directory,}
\PYG{c+c1}{\PYGZsh{} line14 = filename for day list to process,}
\PYG{c+c1}{\PYGZsh{} line15 = filename for zmap catalog,}
\PYG{c+c1}{\PYGZsh{} line16 = template start number,}
\PYG{c+c1}{\PYGZsh{} line17 = template stop number(if line16==0  and line17==0 all templates are processed,}
\PYG{c+c1}{\PYGZsh{} line18 = multiplying factor for MAD to determine threshold }
\PYG{c+c1}{\PYGZsh{} line 19 = multiplying factor to remove daily cft channels with std greater than (average std from all channels * factor at at line 19) }
\PYG{c+c1}{\PYGZsh{} line 20 = multiplying factor to remove daily cft channels with std smaller than (average std from all channels * factor at at line 20)}
\PYG{c+c1}{\PYGZsh{} line 21 = maximum number of templates to be used in template matching (choice is made preferring the closest channels)}
\PYG{c+c1}{\PYGZsh{} line 22 = number of chunks per day (1=86400s, 2=43200, 3=28800, 4=21600, 6=14400 etc... icreasing the factor allows reducing memory consumption) }
\PYG{n}{APEC} \PYG{n}{ATBU} \PYG{n}{ATCA} \PYG{n}{ATCC} \PYG{n}{ATFO} \PYG{n}{ATLO} \PYG{n}{ATPC} \PYG{n}{ATPI} \PYG{n}{ATSC} \PYG{n}{ATVO} \PYG{n}{BADI} \PYG{n}{FOSV} \PYG{n}{FRON} \PYG{n}{MURB} \PYG{n}{NARO} \PYG{n}{PARC} \PYG{n}{PIEI} \PYG{n}{PE3} \PYG{n}{SSFR}
\PYG{n}{EHE} \PYG{n}{EHN} \PYG{n}{EHZ} \PYG{n}{HHE} \PYG{n}{HHN} \PYG{n}{HHZ}
\PYG{n}{IV}
\PYG{l+m+mf}{3.0}
\PYG{l+m+mf}{8.0}
\PYG{l+m+mi}{6}
\PYG{l+m+mf}{0.35}
\PYG{l+m+mi}{6}
\PYG{l+m+mi}{5}
\PYG{l+m+mi}{6}
\PYG{l+m+mi}{24}\PYG{n}{h}
\PYG{n}{template}
\PYG{n}{ttimes}
\PYG{n}{lista1}
\PYG{n}{templates}\PYG{o}{.}\PYG{n}{zmap}
\PYG{l+m+mi}{200}
\PYG{l+m+mi}{203}
\PYG{l+m+mi}{8}
\PYG{l+m+mf}{1.5}
\PYG{l+m+mf}{0.25}
\PYG{l+m+mi}{12}
\PYG{l+m+mi}{6}
\end{sphinxVerbatim}

Needed input files:
\begin{itemize}
\item {} 
Events in a catalog: e.g. templates.zmap (quakeml or zmap format) see ObsPy for format

\item {} 
Suitable velocity model for computing travel times

\item {} 
Station inventory (format consistent with ObsPy read\_inventory routine see \sphinxurl{https://docs.obspy.org/packages/autogen/obspy.core.inventory.inventory.read\_inventory.html})

\item {} 
Days to process: one column file including days to process e.g. lista1

\item {} 
Set parameters: e.g. parameters24

\item {} 
Input directory ./template where trimmed templates are found

\item {} 
Input directory ./24h where 24 hours continuous waveforms are stores

\item {} 
Input directory /ttimes (find moveout times from different channels used to synchronize cross-correlation functions)

\end{itemize}

Output:
\begin{itemize}
\item {} 
Output files .cat, .stats, .stats.mag, .except (details on the output )

\end{itemize}

Detections (.cat)

Detections are listed in a .cat file (e.g. 200.100723.cat)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m+mi}{200} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T02}\PYG{p}{:}\PYG{l+m+mi}{20}\PYG{p}{:}\PYG{l+m+mf}{29.833321}\PYG{n}{Z} \PYG{l+m+mf}{0.18} \PYG{l+m+mf}{0.624} \PYG{l+m+mf}{19.077} \PYG{l+m+mf}{0.388} \PYG{l+m+mf}{11.855} \PYG{l+m+mi}{11}
\PYG{l+m+mi}{200} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T06}\PYG{p}{:}\PYG{l+m+mi}{22}\PYG{p}{:}\PYG{l+m+mf}{08.273321}\PYG{n}{Z} \PYG{l+m+mf}{0.4} \PYG{l+m+mf}{0.565} \PYG{l+m+mf}{16.951} \PYG{l+m+mf}{0.289} \PYG{l+m+mf}{8.667} \PYG{l+m+mi}{10}
\PYG{l+m+mi}{200} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T06}\PYG{p}{:}\PYG{l+m+mi}{46}\PYG{p}{:}\PYG{l+m+mf}{09.553321}\PYG{n}{Z} \PYG{l+m+mf}{0.55} \PYG{l+m+mf}{0.652} \PYG{l+m+mf}{19.56} \PYG{l+m+mf}{0.351} \PYG{l+m+mf}{10.526} \PYG{l+m+mi}{11}
\PYG{l+m+mi}{200} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T22}\PYG{p}{:}\PYG{l+m+mi}{20}\PYG{p}{:}\PYG{l+m+mf}{57.553321}\PYG{n}{Z} \PYG{l+m+mf}{1.88} \PYG{l+m+mf}{1.0} \PYG{l+m+mf}{28.431} \PYG{l+m+mf}{0.361} \PYG{l+m+mf}{10.273} \PYG{l+m+mi}{12}
\PYG{l+m+mi}{200} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T22}\PYG{p}{:}\PYG{l+m+mi}{32}\PYG{p}{:}\PYG{l+m+mf}{10.713321}\PYG{n}{Z} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.35} \PYG{l+m+mf}{0.499} \PYG{l+m+mf}{14.198} \PYG{l+m+mf}{0.318} \PYG{l+m+mf}{9.04} \PYG{l+m+mi}{10}
\PYG{l+m+mi}{200} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T22}\PYG{p}{:}\PYG{l+m+mi}{42}\PYG{p}{:}\PYG{l+m+mf}{34.113321}\PYG{n}{Z} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.02} \PYG{l+m+mf}{0.555} \PYG{l+m+mf}{15.773} \PYG{l+m+mf}{0.292} \PYG{l+m+mf}{8.302} \PYG{l+m+mi}{11}
\PYG{l+m+mi}{200} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T22}\PYG{p}{:}\PYG{l+m+mi}{53}\PYG{p}{:}\PYG{l+m+mf}{24.393321}\PYG{n}{Z} \PYG{l+m+mf}{0.72} \PYG{l+m+mf}{0.642} \PYG{l+m+mf}{18.254} \PYG{l+m+mf}{0.282} \PYG{l+m+mf}{8.012} \PYG{l+m+mi}{12}
\PYG{l+m+mi}{200} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T23}\PYG{p}{:}\PYG{l+m+mi}{09}\PYG{p}{:}\PYG{l+m+mf}{24.953321}\PYG{n}{Z} \PYG{l+m+mf}{1.77} \PYG{l+m+mf}{0.675} \PYG{l+m+mf}{19.178} \PYG{l+m+mf}{0.407} \PYG{l+m+mf}{11.568} \PYG{l+m+mi}{12}
\end{sphinxVerbatim}

Columns in 200.100723.cat file are:
\begin{itemize}
\item {} 
1.Template number corresponding to the python line index in file templates.zmap (event catalog)

\item {} 
2.UTC Date and Time (2010-07-23T02:20:29.833321Z) Time precision selection is possible in parameters24 input file

\item {} 
3.Magnitude estimated as in Peng and Zhao (2009). The magnitude of the detected event is calculated as the median value of the maximum amplitude ratios for all channels between the template and detected event, assuming that a 10-fold increase in amplitude corresponds to a one-unit increase in magnitude.

\item {} 
4.Average cross-correlation estimated from the channels that concurred to the detection. This value is estimated using a time shift between the channels that optimized the stacked CFT.

\item {} 
5.Threshold value (ratio between the amplitude of the CFT stacking and the daily MAD Median Absolute Deviation). The higher the threshold the most probable the detection. This value is estimated using a time shift between the channels that optimized the stacked CFT.

\item {} 
6.Average cross-correlation estimated from the channels that concurred to the detection at no time shift.

\item {} 
7.Threshold value (ratio between the amplitude of the CFT stacking and the daily MAD Median Absolute Deviation). No time shift of the signal cross-correlation functions is allowed.

\item {} 
8.Number of channels for which the cross-correlation is over a certain lower bound (e.g. 0.35)

\end{itemize}

Single Channel Statistics is listed in a .stats file (e.g. 200.100723.stats)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATFO} \PYG{n}{HHE} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.010616075281} \PYG{l+m+mf}{0.721025616044} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATFO} \PYG{n}{HHZ} \PYG{l+m+mf}{0.283285750909} \PYG{l+m+mf}{0.66306439801} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATLO} \PYG{n}{EHE} \PYG{l+m+mf}{0.777449171081} \PYG{l+m+mf}{0.777449171081} \PYG{l+m+mf}{0.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATLO} \PYG{n}{EHN} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0852349513925} \PYG{l+m+mf}{0.650466054757} \PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATLO} \PYG{n}{EHZ} \PYG{l+m+mf}{0.322139846713} \PYG{l+m+mf}{0.366398836428} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{4.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATPI} \PYG{n}{EHE} \PYG{l+m+mf}{0.537447491069} \PYG{l+m+mf}{0.650271304516} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATVO} \PYG{n}{HHE} \PYG{l+m+mf}{0.435372478132} \PYG{l+m+mf}{0.435372478132} \PYG{l+m+mf}{0.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATVO} \PYG{n}{HHN} \PYG{l+m+mf}{0.573539172544} \PYG{l+m+mf}{0.573539172544} \PYG{l+m+mf}{0.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATVO} \PYG{n}{HHZ} \PYG{l+m+mf}{0.133907687217} \PYG{l+m+mf}{0.346238209304} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{MURB} \PYG{n}{HHE} \PYG{l+m+mf}{0.435748932184} \PYG{l+m+mf}{0.792480883079} \PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{MURB} \PYG{n}{HHN} \PYG{l+m+mf}{0.452987060234} \PYG{l+m+mf}{0.713344389699} \PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{MURB} \PYG{n}{HHZ} \PYG{l+m+mf}{0.794985414714} \PYG{l+m+mf}{0.794985414714} \PYG{l+m+mf}{0.0} 
\PYG{l+m+mi}{100723} \PYG{l+m+mi}{200} \PYG{l+m+mi}{0} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T02}\PYG{p}{:}\PYG{l+m+mi}{20}\PYG{p}{:}\PYG{l+m+mf}{29.833321}\PYG{n}{Z} \PYG{l+m+mf}{0.18} \PYG{l+m+mf}{1.88} \PYG{l+m+mf}{11.0} \PYG{l+m+mf}{0.0326947876687} \PYG{l+m+mf}{0.624} \PYG{l+m+mf}{19.077} \PYG{l+m+mf}{0.388} \PYG{l+m+mf}{11.855} \PYG{l+m+mf}{12.0} \PYG{l+m+mf}{9.0} \PYG{l+m+mf}{5.0} \PYG{l+m+mf}{0.0}
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATFO} \PYG{n}{HHE} \PYG{l+m+mf}{0.044988233346} \PYG{l+m+mf}{0.231377904481} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{5.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATFO} \PYG{n}{HHZ} \PYG{l+m+mf}{0.149551602865} \PYG{l+m+mf}{0.420184950211} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATLO} \PYG{n}{EHE} \PYG{l+m+mf}{0.224489982653} \PYG{l+m+mf}{0.664636238755} \PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATLO} \PYG{n}{EHN} \PYG{l+m+mf}{0.631160567096} \PYG{l+m+mf}{0.631160567096} \PYG{l+m+mf}{0.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATLO} \PYG{n}{EHZ} \PYG{l+m+mf}{0.033085860272} \PYG{l+m+mf}{0.262689503234} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{3.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATPI} \PYG{n}{EHE} \PYG{l+m+mf}{0.0362705954363} \PYG{l+m+mf}{0.610553204714} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATVO} \PYG{n}{HHE} \PYG{l+m+mf}{0.297118217589} \PYG{l+m+mf}{0.525933024914} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATVO} \PYG{n}{HHN} \PYG{l+m+mf}{0.36078302459} \PYG{l+m+mf}{0.403840027808} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{ATVO} \PYG{n}{HHZ} \PYG{l+m+mf}{0.482921869799} \PYG{l+m+mf}{0.482921869799} \PYG{l+m+mf}{0.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{MURB} \PYG{n}{HHE} \PYG{l+m+mf}{0.0567199403744} \PYG{l+m+mf}{0.857500320272} \PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{MURB} \PYG{n}{HHN} \PYG{l+m+mf}{0.287008419281} \PYG{l+m+mf}{0.828772698562} \PYG{l+m+mf}{1.0} 
\PYG{n}{IV}\PYG{o}{.}\PYG{n}{MURB} \PYG{n}{HHZ} \PYG{l+m+mf}{0.864438991339} \PYG{l+m+mf}{0.864438991339} \PYG{l+m+mf}{0.0} 
\PYG{l+m+mi}{100723} \PYG{l+m+mi}{200} \PYG{l+m+mi}{0} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T06}\PYG{p}{:}\PYG{l+m+mi}{22}\PYG{p}{:}\PYG{l+m+mf}{08.273321}\PYG{n}{Z} \PYG{l+m+mf}{0.4} \PYG{l+m+mf}{1.88} \PYG{l+m+mf}{10.0} \PYG{l+m+mf}{0.0333501008197} \PYG{l+m+mf}{0.565} \PYG{l+m+mf}{16.951} \PYG{l+m+mf}{0.289} \PYG{l+m+mf}{8.667} \PYG{l+m+mf}{10.0} \PYG{l+m+mf}{7.0} \PYG{l+m+mf}{3.0} \PYG{l+m+mf}{0.0}
\end{sphinxVerbatim}

Columns in 200.100723.stats file are:
\begin{itemize}
\item {} 
1.Network.Station

\item {} 
2.Channel

\item {} 
3.Cross-correlation value at no time shift

\item {} 
4.Cross-correlation value with time shift (nsamples) as in column 5

\item {} 
5.Time shift in nsamples (e.g. -1.0 means that the shift is equal to 0.05 at 20Hz sampling rate)

\end{itemize}

At the end of each trace id you find other parameters related to the detection in part repeating the detection parameters
in .cat file and in part related to the cross-correlations values over some limits (0.3 - 0.5 - 0.7 - 0.9).
\begin{itemize}
\item {} 
date, template\_num, detection\_num, date\&time, template\_magnitude, detection\_magnitude, threshold\_fixed, MAD, ave\_crosscc, threshold\_record, ave\_crosscc\_0, threshold\_record\_0, num\_channels\_gt0.3, num\_channels\_gt0.5, num\_channels\_gt0.7, num\_channels\_gt0.9

\item {} 
100723 201 0 2010-07-23T22:20:57.712239Z 1.51 0.07 9.0 0.0342230009997 0.486 14.193 0.301 8.796 11.0 5.0 2.0 0.0

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ATLO}\PYG{o}{.}\PYG{n}{EHZ} \PYG{l+m+mf}{0.596105028863}
\PYG{n}{ATLO}\PYG{o}{.}\PYG{n}{EHE} \PYG{l+m+mf}{0.170393549956}
\PYG{n}{ATLO}\PYG{o}{.}\PYG{n}{EHN} \PYG{l+m+mf}{0.373070244109}
\PYG{n}{ATVO}\PYG{o}{.}\PYG{n}{HHE} \PYG{l+m+mf}{0.329951522763}
\PYG{n}{ATVO}\PYG{o}{.}\PYG{n}{HHZ} \PYG{l+m+mf}{0.42550877913}
\PYG{n}{ATVO}\PYG{o}{.}\PYG{n}{HHN} \PYG{l+m+mf}{0.0483225655661}
\PYG{n}{MURB}\PYG{o}{.}\PYG{n}{HHZ} \PYG{l+m+mf}{0.191841464532}
\PYG{n}{MURB}\PYG{o}{.}\PYG{n}{HHE} \PYG{l+m+mf}{0.0947942692072}
\PYG{n}{MURB}\PYG{o}{.}\PYG{n}{HHN} \PYG{l+m+mf}{0.171838180932}
\PYG{n}{ATPI}\PYG{o}{.}\PYG{n}{EHE} \PYG{l+m+mf}{0.250359739024}
\PYG{n}{ATFO}\PYG{o}{.}\PYG{n}{HHZ} \PYG{l+m+mf}{0.145329568414}
\PYG{n}{ATFO}\PYG{o}{.}\PYG{n}{HHE} \PYG{l+m+mf}{0.201548385896}
\PYG{l+m+mi}{100723} \PYG{l+m+mi}{200} \PYG{l+m+mi}{0} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T02}\PYG{p}{:}\PYG{l+m+mi}{20}\PYG{p}{:}\PYG{l+m+mf}{29.833321}\PYG{n}{Z} \PYG{l+m+mf}{0.18} \PYG{l+m+mf}{1.88} \PYG{l+m+mf}{11.0} \PYG{l+m+mf}{0.0326947876687} \PYG{l+m+mf}{0.624} \PYG{l+m+mf}{19.077} \PYG{l+m+mf}{0.388} \PYG{l+m+mf}{11.855} \PYG{l+m+mf}{12.0} \PYG{l+m+mf}{9.0} \PYG{l+m+mf}{5.0} \PYG{l+m+mf}{0.0}
\PYG{n}{ATLO}\PYG{o}{.}\PYG{n}{EHZ} \PYG{l+m+mf}{0.388076513533}
\PYG{n}{ATLO}\PYG{o}{.}\PYG{n}{EHE} \PYG{l+m+mf}{0.292051072606}
\PYG{n}{ATLO}\PYG{o}{.}\PYG{n}{EHN} \PYG{l+m+mf}{0.495577417282}
\PYG{n}{ATVO}\PYG{o}{.}\PYG{n}{HHE} \PYG{l+m+mf}{0.351604524548}
\PYG{n}{ATVO}\PYG{o}{.}\PYG{n}{HHZ} \PYG{l+m+mf}{0.379804503709}
\PYG{n}{ATVO}\PYG{o}{.}\PYG{n}{HHN} \PYG{l+m+mf}{0.144512967971}
\PYG{n}{MURB}\PYG{o}{.}\PYG{n}{HHZ} \PYG{l+m+mf}{0.495658912113}
\PYG{n}{MURB}\PYG{o}{.}\PYG{n}{HHE} \PYG{l+m+mf}{0.331121201612}
\PYG{n}{MURB}\PYG{o}{.}\PYG{n}{HHN} \PYG{l+m+mf}{0.497348207422}
\PYG{n}{ATPI}\PYG{o}{.}\PYG{n}{EHE} \PYG{l+m+mf}{0.151842475707}
\PYG{n}{ATFO}\PYG{o}{.}\PYG{n}{HHZ} \PYG{l+m+mf}{0.36823188478}
\PYG{n}{ATFO}\PYG{o}{.}\PYG{n}{HHE} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.00476247218528}
\PYG{l+m+mi}{100723} \PYG{l+m+mi}{200} \PYG{l+m+mi}{0} \PYG{l+m+mi}{2010}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{07}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{23}\PYG{n}{T06}\PYG{p}{:}\PYG{l+m+mi}{22}\PYG{p}{:}\PYG{l+m+mf}{08.273321}\PYG{n}{Z} \PYG{l+m+mf}{0.4} \PYG{l+m+mf}{1.88} \PYG{l+m+mf}{10.0} \PYG{l+m+mf}{0.0333501008197} \PYG{l+m+mf}{0.565} \PYG{l+m+mf}{16.951} \PYG{l+m+mf}{0.289} \PYG{l+m+mf}{8.667} \PYG{l+m+mf}{10.0} \PYG{l+m+mf}{7.0} \PYG{l+m+mf}{3.0} \PYG{l+m+mf}{0.0}
\end{sphinxVerbatim}

Columns in 200.100723.stats.mag file are:
\begin{itemize}
\item {} 
1.Station.Channel Mag.

\item {} 
2.date, template\_num, detection\_num, date\&time, template\_magnitude, detection\_magnitude, threshold\_fixed, MAD, ave\_crosscc, threshold\_record, ave\_crosscc\_0, threshold\_record\_0, num\_channels\_gt0.3, num\_channels\_gt0.5, num\_channels\_gt0.7, num\_channels\_gt0.9

\item {} 
3.100723 201 0 2010-07-23T22:20:57.712239Z 1.51 0.07 9.0 0.0342230009997 0.486 14.193 0.301 8.796 11.0 5.0 2.0 0.0

\end{itemize}

Note that input and output file names, inventories, template catalogs, velocity models are recalled also in the next steps and remain almost fixed. Parameters in files .par could change.
\sphinxhref{https://github.com/avuan/PyMPA37/releases}{\sphinxincludegraphics[width=100\sphinxpxdimen]{{pympa_logo1}.png}}

\chapter{Creating an output catalog and verify detections}
\label{\detokenize{output:creating-an-output-catalog-and-verify-detections}}\label{\detokenize{output::doc}}
It consists of some separate utilities in , post-processing tools to obtain a catalog and verify events.
Many events could be correlated to more than one template in a narrow time window. A fixed time window length can be selected, and within each, the template for which the normalized cross-correlation coefficient is the greates provides the event location and data to determine the magnitude.
This process is run by \textless{}./sub/output.process\_detections\textgreater{} in to two steps, by using the last event origin time as a reference to set the next time window scrutinized.
If template matching performs well and input data are reliable we expect you are able to increase your catalog.
\sphinxhref{https://github.com/avuan/PyMPA37/releases}{\sphinxincludegraphics[width=800\sphinxpxdimen]{{catalog_improvement}.png}}
Figure - 5 years template events along the Alto-Tiberina fault (blue histograms) as recorded by ATF test bed and augmented detections by PyMPA (orange). Solid lines represent the cumulative number of earthquakes. In the inset the magnitude distribution of the templates in comparison with the augmented catalog. The completeness magnitude is decreased by 0.5. Stars indicate the timing of eartquakes between magnitude 2 and 2.8.

The final catalog should be verified by visual inspection for a number of sampled detections. Generally, we proceed by verification of events having low thresholds to understand a safe value to validate the catalog. The routine \textless{}./sub/output.verify\_detection\textgreater{} creates graphs of time windows where continuous data and trimmed templates are plotted with info grasped from channel by channel cross-correlation process.
\sphinxhref{https://github.com/avuan/PyMPA37/releases}{\sphinxincludegraphics[width=800\sphinxpxdimen]{{repeater}.png}}
Figure - Visual inspection of a repeater with an average cross-correlation value of 0.98 along the Alto-Tiberina fault. Seismic data from ATF test bed (black waveforms) and a template (red) are overlapped. On the left of the panel, we list the station and channel codes, and on the right the corresponding value of cross-correlation between the two events. The template event (a magnitude M=-0.4) allows to detect a M=-1.0 repeater.

Important: we recommend to use an updated version of .

These utilities contains:
\begin{itemize}
\item {} 
{\hyperref[\detokenize{sub/output.process_detections::doc}]{\sphinxcrossref{\DUrole{doc}{Postprocessing routines}}}};

\item {} 
{\hyperref[\detokenize{sub/output.verify_detection::doc}]{\sphinxcrossref{\DUrole{doc}{Visual verification of detections}}}};

\end{itemize}

This package is written by the PyMPA developers, and is distributed under the LGPL GNU Licence, Copyright PyMPA developers 2019.


\section{Contents:}
\label{\detokenize{output:contents}}

\subsection{Process PyMPA Output}
\label{\detokenize{sub/output.process_detections:process-pympa-output}}\label{\detokenize{sub/output.process_detections::doc}}
From the defined template by cross-correlation for a selected day is obtained a list of possible detections.
Since time overlapping detections could be found also by different templates, the procedure allows a search for
the template able to detect the events with the highest threshold value that is also related with the highest
average cross-correlation value for the used network. From the main program, many cat files are daily sorted
and grouped for a scan of the events showing the best detections. A bash script is used to collect data and create the input for the procedure
and a python script is used to filter the result on the basis of the fiter.par parameters used. The filter.par defines
some additional filtering to detections to possibly overcome a visual validation of the new detections.


\subsection{Visual verification of detections}
\label{\detokenize{sub/output.verify_detection:visual-verification-of-detections}}\label{\detokenize{sub/output.verify_detection::doc}}
Visual verification is needed to evaluate problematic cases or estimate a
safe threshold to validate the catalog of detections. Visual verification needs the new detections
catalog, the templates.zmap list, the daily template detections (e.g. 230.140913.cat file) and relative
statistics (e.g. 230.140913.stats)cat file) and relative
statistics (e.g. 230.140913.stats)cat file) and relative
statistics (e.g. 230.140913.stats). The verify.par parameters allow for selecting the stations, frequency range,
and window length for the visual verification.
\sphinxhref{https://github.com/avuan/PyMPA37/releases}{\sphinxincludegraphics[width=100\sphinxpxdimen]{{pympa_logo1}.png}}


\renewcommand{\indexname}{Index}
\printindex
\end{document}